{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=api_key,\n",
    "             model_name=\"gpt-3.5-turbo\", max_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object TwitterTweetScraper.get_items at 0x000001D66A736340>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tweet_id = 1629481601116811265\n",
    "\n",
    "tweets = sntwitter.TwitterTweetScraper(tweet_id, mode=\"recurse\").get_items()\n",
    "\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m username \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mslowburninfuse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m getdata \u001b[39m=\u001b[39m sntwitter\u001b[39m.\u001b[39mTwitterUserScraper(username)\u001b[39m.\u001b[39mget_items()\n\u001b[1;32m----> 3\u001b[0m getdata_dict \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(getdata)\n\u001b[0;32m      5\u001b[0m getdata_dict\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\modules\\twitter.py:1755\u001b[0m, in \u001b[0;36mTwitterUserScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1753\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isUserId \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1754\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfrom:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1755\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_items()\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\modules\\twitter.py:1661\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1658\u001b[0m params \u001b[39m=\u001b[39m paginationParams\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m   1659\u001b[0m \u001b[39mdel\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[39m'\u001b[39m, _TwitterAPIType\u001b[39m.\u001b[39mV2, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor):\n\u001b[0;32m   1662\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v2_timeline_instructions_to_tweets_or_users(obj)\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\modules\\twitter.py:761\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 761\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, apiType, reqParams)\n\u001b[0;32m    762\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    764\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\modules\\twitter.py:727\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, apiType, params)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mif\u001b[39;00m apiType \u001b[39mis\u001b[39;00m _TwitterAPIType\u001b[39m.\u001b[39mGRAPHQL:\n\u001b[0;32m    726\u001b[0m \tparams \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39murlencode({k: json\u001b[39m.\u001b[39mdumps(v, separators \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}, quote_via \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39mquote)\n\u001b[1;32m--> 727\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response)\n\u001b[0;32m    728\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m \tobj \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\base.py:251\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 251\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\snscrape\\base.py:203\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[0;32m    201\u001b[0m \t_logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m... with environmentSettings: \u001b[39m\u001b[39m{\u001b[39;00menvironmentSettings\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m \tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39msend(req, allow_redirects \u001b[39m=\u001b[39m allowRedirects, timeout \u001b[39m=\u001b[39m timeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39menvironmentSettings)\n\u001b[0;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    205\u001b[0m \t\u001b[39mif\u001b[39;00m attempt \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries:\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\PF2L6BL6\\anaconda3\\envs\\llm-apps\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "username = \"slowburninfuse\"\n",
    "getdata = sntwitter.TwitterUserScraper(username).get_items()\n",
    "getdata_dict = list(getdata)\n",
    "\n",
    "getdata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object TwitterTweetScraper.get_items at 0x000001D66A736340>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dict = list(tweets)\n",
    "\n",
    "tweets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "def get_tweets(entities, start_date, end_date, num_tweets):\n",
    "    \"\"\"\n",
    "    Scrape tweets for a list of entities within a specified date range and return a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    entities : list\n",
    "        A list of Twitter entities (e.g., usernames, hashtags) to search for.\n",
    "    start_date : str\n",
    "        The start date for the search in YYYY-MM-DD format.\n",
    "    end_date : str\n",
    "        The end date for the search in YYYY-MM-DD format.\n",
    "    num_tweets : int\n",
    "        The number of tweets to scrape for each entity.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the scraped tweets for all entities.\n",
    "        Columns: entity, url, postedTime, tweetText, id, username, retweetCount, likeCount, quoteCount, viewCount,\n",
    "        scrapedTime, date, month, year\n",
    "    \"\"\"\n",
    "    all_tweets_df = pd.DataFrame()\n",
    "\n",
    "    for entity in entities:\n",
    "        # Build the Twitter search query\n",
    "        query = f'\"{entity}\" since:{start_date} until:{end_date}'\n",
    "\n",
    "        # Scrape tweets using Snscrape\n",
    "        tweet_df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(query).get_items(), num_tweets))\n",
    "\n",
    "        # Clean up and rename columns\n",
    "        tweet_df[\"entity\"] = entity\n",
    "        tweet_df = tweet_df[['entity', 'url', 'date', 'renderedContent', 'id', 'user', 'likeCount', 'retweetCount', 'quoteCount', 'viewCount']]\n",
    "        tweet_df.rename(columns={'date': 'postedTime', 'renderedContent': 'tweetText'}, inplace=True)\n",
    "\n",
    "        # Extract the username from the user column and drop the original user column\n",
    "        tweet_df.loc[:, \"username\"] = tweet_df.loc[:, \"user\"].apply(lambda x: x[\"username\"])\n",
    "        tweet_df.drop(['user'], axis=1, inplace=True)\n",
    "\n",
    "        # Add columns for the scraped time, date, month, and year\n",
    "        jakarta_timezone = pytz.timezone('Asia/Jakarta')\n",
    "        current_time = datetime.datetime.now(tz=jakarta_timezone)\n",
    "        tweet_df['scrapedTime'] = pd.to_datetime(current_time)\n",
    "        tweet_df['time'] = tweet_df['scrapedTime'].dt.strftime('%H:%M')\n",
    "        tweet_df['date'] = tweet_df['scrapedTime'].dt.date\n",
    "        tweet_df['month'] = tweet_df['scrapedTime'].dt.month\n",
    "        tweet_df['year'] = tweet_df['scrapedTime'].dt.year\n",
    "\n",
    "        # Concat the tweets for this entity to the overall DataFrame\n",
    "        all_tweets_df = pd.concat([all_tweets_df, tweet_df], ignore_index=True)\n",
    "\n",
    "    return all_tweets_df\n",
    "\n",
    "\n",
    "# List of top Indonesian politicians\n",
    "politicians = [\"Prabowo\", \"Puan Maharani\", \"Anies Baswedan\", \"Jokowi\", \"Pemilu\", \"Ganjar\"]\n",
    "\n",
    "# Get dates two days before today and today\n",
    "today = datetime.date.today()\n",
    "two_days_before = today - datetime.timedelta(days=2)\n",
    "\n",
    "# Call the function with the updated list and dates\n",
    "politician_tweets_df = get_tweets(politicians, two_days_before, today, 10)\n",
    "display(politician_tweets_df, politician_tweets_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../cleaned-article.txt\") as f:\n",
    "    article = f.read()\n",
    "\n",
    "texts = text_splitter.split_text(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Arman terperanjat saat ditawari endorsement yang nilainya delapan kali lipat dari yang biasa ia terima. Tawaran itu datang dari rumah judi online. Jika biasanya ia dibayar Rp1 juta untuk satu postingan, ia ditawari Rp8 juta. Tawaran itu jelas menggiurkan. Arman bukan nama sebenarnya. Usia 24, domisili Semarang. Pengikutnya di Instagram 300 ribuan. Ia rutin mengunggah konten-konten seputar esport: mulai dari panduan mekanik untuk hero dalam permainan MOBA (Multiplayer Online Battle Arena), tips dan trik, sampai trivia tim-tim esport yang berkompetisi di liga lokal. Selain itu, Arman juga streamer yang kontennya diunggah di YouTube.\\n\\nEndorsement yang sebelumnya pernah ia ambil antara lain dari gerai top-up gim daring dan produk digital, brand pakaian, minuman kemasan saset, dan dagangan temannya. Rumah judi online itu meminta Arman mempromosikan permainan slot di situsweb mereka. Rinciannya, Rp8 juta untuk satu postingan di feed dengan format bebas (foto atau video pendek), membubuhkan logo, plus copy ringkas promo yang ditawarkan. Arman meminta pendapat temannya sesama selebgram. Temannya menyarankan terima saja. “Akhirnya saya terima,” katanya. Setelah konten endorsement diunggah, beberapa temannya menghubungi. Ada yang berseloroh nilainya pasti besar, ada yang bertanya kenapa mau, ada juga yang memujinya nyali besar.\\n\\nMenurut Naldo, tokoh kita di tulisan pertama, itu memang praktik umum di rumah-rumah judi online—selain menggunakan Google Ads. “Orang marketing pernah saya tugasin cari artis atau penyanyi dangdut,” katanya, “tapi hanya ada satu yang mau. Sisanya menolak karena takut diciduk.” Nilainya Rp15 juta per postingan.\\n\\nRumah judi Naldo sengaja menyasar pengikut penyanyi dangdut, karena mereka adalah para pekerja atau kelompok sosial yang sehari-hari memang lekat dengan judi online yang sangat mudah diakses. Entah itu slot, tebak nomor, atau tebak skor. “Waktu itu saya siapkan budget sekitar Rp200 juta.”\\n\\nBeberapa kenalan Naldo yang mengoperasikan rumah judi juga melakukan hal yang sama. Bedanya di tipe artis atau influencer. Ada yang lebih suka aktor, atau komedian, atau musisi, atau model yang punya rekam jejak di majalah pria dewasa, atau selebgram dan streamer seperti Arman.\\n\\nPada Mei 2017, Nikita Mirzani mempromosikan Jaya Bet lewat unggahan di akun Instagramnya. Di caption unggahan Nikita, tertera pilihan permainan yang Jaya Bet sediakan. Selain Nikita, masih ada artis lain yang kemudian menerima endorsement dari rumah judi online yang sama. Antara lain Amanda Manopo, Chelsea Veronnia yang merupakan sepupu selebgram ternama Rachel Venya, dan terakhir ada Sheila Marcia. Ketiganya mempromosikan juga situs Jaya Bet lewat akun Instagram masing-masing, berselang sekitar satu bulan dari unggahan Nikita.\\n\\nKarena unggahan itu, Nikita Mirzani dilaporkan ke kepolisian. Amanda, Chelsea, dan Sheila beruntung tidak sampai dilaporkan, tapi mereka kemudian menghapus unggahan. Tidak hanya lewat Instagram, beberapa nama besar artis lain memanfaatkan YouTube. Salah satunya Dewi Persik, yang mempromosikan situs M11 Slot. Komedian Denny Cagur, yang mempromosikan Agen 138 di unggahan YouTube Short Hoki Slot. Nama besar lain, penyanyi kondang Ari Lasso dan artis multi talenta Boy William, turut juga mempromosikan Agen 138.\\n\\nYang menarik, para artis itu mengganti frasa \"judi online\" dengan \"game online\". Dan mereka mengulang-ulang kalimat \"game online ini sudah mempunyai lisensi dan terakreditasi\". Lisensi dari siapa? Akreditasi macam apa? Tidak jelas. Tapi bayaran mereka pasti berpuluh kali lipat dari yang diterima Arman.\\n\\nSetelah dua minggu, Arman kemudian menghapus unggahan endorsement dari rumah judi. Kerja samanya memang hanya untuk jangka waktu dua minggu. Sejak saat itu, Arman mengaku kapok. \"Resikonya enggak main-main. Bisa dipenjara saya. Yang aman-aman aja, deh,\" katanya.', lookup_str='', metadata={}, lookup_index=0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [Document(page_content=t) for t in texts[:1]]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Influencers and celebrities in Indonesia are being offered large sums of money to promote online gambling sites on their social media accounts. The practice is common among online gambling houses, who target those with large followings on Instagram and YouTube. The celebrities often use euphemisms such as \"game online\" instead of \"gambling\" and claim that the sites are licensed and accredited. However, the industry is largely unregulated and has been linked to money laundering, drug and human trafficking, and prostitution. The Global Initiative Against Transnational Organized Crime has identified the Asia-Pacific region as the largest and fastest-growing gambling market in the world. The Indonesian government has taken action against those promoting online gambling, with penalties including up to 10 years in prison and fines of up to IDR 1 billion ($70,000).'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['Sebuah artikel di Tirto.id membahas tentang praktik endorsement oleh rumah judi online kepada selebgram dan artis di Indonesia. Beberapa selebgram dan artis telah menerima tawaran endorsement dari rumah judi online dengan bayaran yang jauh lebih besar dari biasanya. Mereka diminta untuk mempromosikan permainan slot di situs web judi online tersebut. Beberapa di antaranya adalah Nikita Mirzani, Amanda Manopo, Chelsea Veronnia, Sheila Marcia, Dewi Persik, Denny Cagur, Ari Lasso, dan Boy William. Mereka mengganti frasa \"judi online\" dengan \"game online\" dan mengulang-ulang kalimat \"game online ini sudah mempunyai lisensi dan terakreditasi\". Namun, praktik ini ilegal dan berisiko bagi selebgram dan artis yang terlibat. Beberapa di antaranya telah dilaporkan ke kepolisian.'],\n",
       " 'output_text': 'Beberapa selebgram dan artis di Indonesia telah menerima tawaran endorsement dari rumah judi online dengan bayaran yang jauh lebih besar dari biasanya untuk mempromosikan permainan slot di situs web judi online tersebut. Namun, praktik ini ilegal dan berisiko bagi selebgram dan artis yang terlibat. Beberapa di antaranya telah dilaporkan ke kepolisian.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\" Write a concise summary of the following article:\n",
    "\n",
    "{text}\n",
    "\n",
    "CONCISE SUMMARY IN BAHASA INDONESIA:\n",
    "\"\"\"\n",
    "\n",
    "myprompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(OpenAI(temperature=0, openai_api_key=api_key, model_name=\"gpt-3.5-turbo\"), \n",
    "                             chain_type=\"map_reduce\", return_intermediate_steps=True,\n",
    "                             map_prompt=myprompt, combine_prompt=myprompt)\n",
    "\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
